# -*- coding: utf-8 -*-
"""EE782_A2_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EwPnwM85yc_Sza0p4hNBEURFuNM9aeu4
"""

## Mounting Google Drive in the Colab environment
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

## Importing necessary libraries and modules
import os
import random
import shutil
import tarfile
import itertools

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import optim
import torchvision.utils as vutils
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import ExponentialLR
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import transforms
from PIL import Image

## Check for availability of T4-GPU's
if torch.cuda.is_available():
    gpu = torch.cuda.get_device_name(0)
    print(f"GPU: {gpu}")
else:
    print("No GPU available.")

## Initializing the path of the zipped file
file_path = '/content/drive/My Drive/lfw.tgz'

## Creating a new directory to extract the images
extraction_dir = '/content/drive/My Drive/Assignment2_Data'

## Extracting the zipped file to the desired location using tarfile
with tarfile.open(file_path, 'r:gz') as tar:
  tar.extractall(path = extraction_dir)

## Initializing the base directory to work with
base_directory = '/content/drive/My Drive/Assignment2_Data/lfw'

## Obtaining the list of all subdirectories i.e. folder names
subdirectories = [d for d in os.listdir(base_directory)]
random.seed(2023)

## Randomly sampling 4096 folders, images from which will be used for training the GAN
selected_folders = random.sample(subdirectories, 4096)
selected_images = []

## Iterating over the folders and randomly selecting one image from each folder and appending them to a list
for folder in selected_folders:
  folder_path = os.path.join(base_directory,folder)
  images = os.listdir(folder_path)
  selected_image = random.choice(images)
  selected_images.append(os.path.join(folder_path, selected_image))

## Creating a DataFrame with all the image paths (Only 1 column)
df = pd.DataFrame(selected_images, columns = ['img_path'])
df.head()

## Creating a class for making a custom dataset which takes the created Dataframe as the input
class CustomDataset(Dataset):
  ## Initializing the dataframe
  def __init__(self, data):
    self.data = data

  ## Range of indices for the DataLoader is equal to the length of the dataset
  def __len__(self):
    return len(self.data)

  ## Returning the image at the required index
  def __getitem__(self,idx):

    ## Extracting the image using PIL from the path at the given index in the DataFrame
    img_path = self.data.iloc[idx][0]
    img = Image.open(img_path)

    ## Processing the image using transforms like resize, center-crop and normalization
    preprocess = transforms.Compose([
      transforms.Resize(256),
      transforms.CenterCrop(224),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    ## Applying the transforms to the image and returning it as a tensor
    img = preprocess(img)
    return img

## Defining hyper-parameters like batch_size and latent space dimension
batch_size = 64
latent_dim = 64

## Creating the dataset suitable for training using the DataLoader class
train_data = CustomDataset(data = df)
train_dataloader = DataLoader(train_data, batch_size = batch_size , shuffle = True)

## Defining the Generator Network
class Generator(nn.Module):
  def __init__(self, latent_dim):
    super(Generator, self).__init__()

    ## Initializing the latent space dimension
    self.latent_dim = latent_dim

    ## First fully connected layer with Input Shape = (bx64), Output Shape = (bx64x14x14)
    self.fc1 = nn.Sequential(
        nn.Linear(latent_dim , latent_dim*14*14),
        nn.ReLU(inplace = True),
    )
    ## First Deconvolution / Transposed Convolution layer to upscale the spatial dimensions by 2
    ## Using batch normalization and ReLU units for stable training
    ## Input Shape = (bx64x14x14) Output Shape = (bx32x28x28)
    self.deconv1 = nn.Sequential(
        nn.ConvTranspose2d(latent_dim, 32, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(32),
        nn.LeakyReLU(0.1, inplace = True),
    )

    ## Input Shape = (bx32x28x28) Output Shape = (bx16x56x56)
    self.deconv2 = nn.Sequential(
        nn.ConvTranspose2d(32, 16, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(16),
        nn.LeakyReLU(0.1, inplace = True),
    )
    ## Input Shape = (bx16x56x56) Output Shape = (bx8x112x112)
    self.deconv3 = nn.Sequential(
        nn.ConvTranspose2d(16, 8, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(8),
        nn.LeakyReLU(0.1, inplace = True),
    )
    ## Input Shape = (bx8x112x112) Output Shape = (bx3x224x224)
    self.deconv4 = nn.Sequential(
        nn.ConvTranspose2d(8, 3, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(3),
        nn.LeakyReLU(0.1, inplace = True),
    )

  ## Defining the forward pass
  def forward(self,x):
    x = self.fc1(x)
    ## Changing the dimensions from (bx64*14*14) to (bx64x14x14)
    x = x.view(-1, self.latent_dim, 14, 14)
    x = self.deconv1(x)
    x = self.deconv2(x)
    x = self.deconv3(x)
    x = self.deconv4(x)
    return x

class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()

    ## batch x 3 x 224 x 224
    self.conv1 = nn.Sequential(
        nn.Conv2d(3,16, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(16),
        nn.LeakyReLU(0.1, inplace = True),
        nn.MaxPool2d(kernel_size = 2, stride = 2),
    )
    ## batch x 16 x 56 x 56
    self.conv2 = nn.Sequential(
        nn.Conv2d(16,32, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(32),
        nn.LeakyReLU(0.1, inplace = True),
        # nn.MaxPool2d(kernel_size = 2, stride = 2),
    )

    ## batch x 32 x 28 x 28
    self.conv3 = nn.Sequential(
        nn.Conv2d(32,64, kernel_size = 4, stride = 2, padding = 1, bias = False),
        nn.BatchNorm2d(64),
        nn.LeakyReLU(0.1, inplace = True),
    )

    ## batch x 64 x 14 x 14
    self.conv4 = nn.Sequential(
        nn.Conv2d(64,128, kernel_size = 4, stride = 2, padding = 1),
        nn.BatchNorm2d(128),
        nn.LeakyReLU(0.1, inplace = True),
        nn.AdaptiveAvgPool2d(1)
    )

    ## batch x 64 x 1 x 1
    self.fc = nn.Sequential(
        nn.Linear(128,1),
        nn.Sigmoid(),
    )

  def forward(self,x):
    x = self.conv1(x)
    x = self.conv2(x)
    x = self.conv3(x)
    x = self.conv4(x)
    x = x.squeeze()
    x = self.fc(x)
    return x

## Initializing the weights for the layers randomly
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

## Creeating an object for the generator and discriminator
GeneratorNet = Generator(64).cuda()
DiscriminatorNet = Discriminator().cuda()

## Applying the weight initialization function for both the generator and discrminator
GeneratorNet.apply(weights_init)
DiscriminatorNet.apply(weights_init)

## Displaying the model descriptions
print(GeneratorNet)
print(DiscriminatorNet)

## Defining the loss criterion for training the GAN (Binary Cross Entropy)
criterion = nn.BCELoss()

## Defining a batch of random noise used as an input to the genrator to generate images at the end of training
random_noise = torch.randn(batch_size, latent_dim).cuda()

## Defining real and fake labels for training and genearated images respectively
real_label = 1
fake_label = 0

## Defining optimizers (Adam) for both the generator and discriminator with default parameters
optimizerG = optim.Adam(GeneratorNet.parameters(), lr = 0.002, betas = (0.5,0.999))
optimizerD = optim.Adam(DiscriminatorNet.parameters(), lr = 0.002, betas = (0.5,0.999))

## Defining the training loop
def train(num_epochs, train_dataloader, real_label, fake_label, g_model, d_model, batch_size, latent_dim):

  ## A list to store the generated images at the end of the training loop
  img_list = []
  ## Accumulating generator losses for every epoch
  G_losses = []
  ## Accumulating discriminator losses for every epoch
  D_losses = []

  ## Setting the networks into training mode
  g_model.train()
  d_model.train()

  ## Iterating over the number of epochs
  for epoch in range(num_epochs):

    ## Iterating over the number of
    for i,img in enumerate(train_dataloader):

      ## Update Discriminator Network
      ## Train for all real images

      optimizerD.zero_grad()
      ## Extracting images and labels
      img = img.cuda()
      label = torch.full((batch_size,), real_label, dtype = torch.float).cuda()

      ## Performing the forward and backward passes
      output = d_model(img).view(-1)
      errD_real = criterion(output, label)
      errD_real.backward()

      ## Training for all fake images
      ## Generating noise using torch.randn
      noise = torch.randn(batch_size, latent_dim).cuda()
      ## Passing it to the generator
      fake_imgs = g_model(noise)
      ## Changing the labels
      label.fill_(fake_label)

      ## Allow G and D to train independently by detaching it from the computation graph
      ## Again computing the forward and backward pass
      output = d_model(fake_imgs.detach()).view(-1)
      errD_fake = criterion(output, label)
      errD_fake.backward()

      ## Adding the errors for real and fake images
      errD = errD_real + errD_fake
      ## Performing weight and LR updates for the Discriminator
      optimizerD.step()

      ## Update Generator Network
      optimizerG.zero_grad()
      ## The fake images are now real for the generator
      label.fill_(real_label)

      ## Performing the forward and backward pass
      output = d_model(fake_imgs).view(-1)
      errG = criterion(output, label)
      errG.backward()
      ## Performing weight and LR updates for the Generator
      optimizerG.step()

      ## Saving the losses to plot them
      G_losses.append(errG.item())
      D_losses.append(errD.item())

      ## Displaying training progress at the start and halfway through each batch for every epoch
      if(i%32 == 0):
        print(f"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_dataloader)}], G_Loss: {errG}, D_Loss: {errD}")

      ## For the last epoch and last batch using the random noise as an input to the generator, generate new images and return them
      if ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):
        with torch.no_grad():
          fake = g_model(random_noise).detach().cpu()
        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

  return G_losses, D_losses, img_list

## Perform model training
G_losses, D_losses, img_list = train(num_epochs = 60, train_dataloader = train_dataloader, real_label = real_label, fake_label = fake_label,
      g_model = GeneratorNet, d_model = DiscriminatorNet, batch_size = batch_size, latent_dim = 64)

## Plotting the generator and discriminator losses for all the epochs
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

## Displaying the generated images
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]

"""As we can see the generated faces almost resemble the actual faces, the model has been able to generate the facial features correctly. Due to computational constraints this is the best we can get. With more training images, deeper networks and epochs we can hope to get images very close to the training set"""